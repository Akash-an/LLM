{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPdp2AbH/ajikxPab9pc7wZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4ed22e213a64625a39112542c53c27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9de41bd80e51462da4cef729a65e3732",
              "IPY_MODEL_948ed778268a4657b88e065a62531205",
              "IPY_MODEL_5fc3ea28fbc14e68a764ebc59481c72a"
            ],
            "layout": "IPY_MODEL_6446f3dd22aa4bebbf49f0c7edc03172"
          }
        },
        "9de41bd80e51462da4cef729a65e3732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9a46174a03a4f6d93baaf5845ad51e9",
            "placeholder": "​",
            "style": "IPY_MODEL_a8aab1a25b9d4a1c956094ba712ab820",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "948ed778268a4657b88e065a62531205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_202983fbc06b4268b4f110a21d5046a6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_783d76ddc9a140c9951127d8016cf159",
            "value": 2
          }
        },
        "5fc3ea28fbc14e68a764ebc59481c72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30c5a8ed8c304a438bfc55adc07a718b",
            "placeholder": "​",
            "style": "IPY_MODEL_cb766dbd22ab407da805a25870485d8e",
            "value": " 2/2 [01:40&lt;00:00, 45.14s/it]"
          }
        },
        "6446f3dd22aa4bebbf49f0c7edc03172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a46174a03a4f6d93baaf5845ad51e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8aab1a25b9d4a1c956094ba712ab820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "202983fbc06b4268b4f110a21d5046a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "783d76ddc9a140c9951127d8016cf159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30c5a8ed8c304a438bfc55adc07a718b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb766dbd22ab407da805a25870485d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akash-an/LLM/blob/master/falcon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install einops\n",
        "!pip install accelerate\n",
        "# !pip install xformers"
      ],
      "metadata": {
        "id": "dRv3UU3mmgFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y24UYMlhl8a"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"tiiuae/falcon-7b-instruct\""
      ],
      "metadata": {
        "id": "YjdlHlWbooeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     \"tiiuae/falcon-7b-instruct\",\n",
        "#     trust_remote_code=True,\n",
        "#     )"
      ],
      "metadata": {
        "id": "RUc-H9EJtFlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model, trust_remote_code=True)\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=200,\n",
        "    max_new_tokens=200,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    #offload_folder=\"offload\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f4ed22e213a64625a39112542c53c27c",
            "9de41bd80e51462da4cef729a65e3732",
            "948ed778268a4657b88e065a62531205",
            "5fc3ea28fbc14e68a764ebc59481c72a",
            "6446f3dd22aa4bebbf49f0c7edc03172",
            "b9a46174a03a4f6d93baaf5845ad51e9",
            "a8aab1a25b9d4a1c956094ba712ab820",
            "202983fbc06b4268b4f110a21d5046a6",
            "783d76ddc9a140c9951127d8016cf159",
            "30c5a8ed8c304a438bfc55adc07a718b",
            "cb766dbd22ab407da805a25870485d8e"
          ]
        },
        "id": "uSWgEubTor3e",
        "outputId": "3db30885-09d3-4e2d-8e79-f1550f563895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4ed22e213a64625a39112542c53c27c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pipeline(\n",
        "    \"Perfectionism is\",\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    #offload_folder=\"offload\",\n",
        ")\n",
        "\n",
        "for seq in sequences:\n",
        "    print(f\"Result: {seq['generated_text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHGNBFwho2JE",
        "outputId": "39c75183-10db-4ee8-d7f6-a6c117c412a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: Perfectionism is a powerful, but dangerous force in the world today. Many individuals who are so driven to succeed in their chosen field become their own worst enemy. They become so obsessed with perfection that they forget the value of taking time to relax, enjoy the present moment, and take care of themselves.\n",
            "When we are always focused on being perfect, we are often so overwhelmed that we forget to take care of our own emotional and mental health. It’s important to take things at a more gentle pace so that we can maintain our overall well-being.\n",
            "The good news is that perfectionism can be overcome with the right help. You can learn from experts and mentors who can show you how to relax, take things at a gentle pace, and find ways to cope with perfectionism.\n",
            "In this article, we’ll discuss why perfection is a dangerous force and how to overcome it.\n",
            "Why Perfection Is Dangerous\n",
            "Perfectionism is often linked to negative health issues. People\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sS_qcSfxFNfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDfDqy_KFNTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "zuub9yoPFM2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install pinecone-client\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMxWWqA1FMq1",
        "outputId": "430bbe3d-993f-41b5-c83b-d9182d8f16f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.300-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.0-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.38 (from langchain)\n",
            "  Downloading langsmith-0.0.40-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.300 langsmith-0.0.40 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0.1)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.5.0)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.4)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n",
            "Installing collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.4.2 loguru-0.7.2 pinecone-client-2.2.4\n",
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model ='text-search-ada-query-001', deployment='text-search-ada-query-001',openai_api_key='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')"
      ],
      "metadata": {
        "id": "KX8FuGuCFLEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=\"f3c13766-bcf7-400b-af08-132714aa70cb\",\n",
        "    environment=\"gcp-starter\"\n",
        ")"
      ],
      "metadata": {
        "id": "6CUJfbUMGkaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"finish\"\n",
        "# search = Pinecone.from_documents(split_text, embeddings, index_name=index_name)\n",
        "search = Pinecone.from_existing_index(index_name, embeddings)"
      ],
      "metadata": {
        "id": "1oOzuh80Iqlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "em = embeddings.embed_query(\"Perfectionism is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kj41JhoNWyh",
        "outputId": "7992f2f1-f1a6-4a81-bc5a-3bfa12ddbcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.embeddings.openai:Warning: model not found. Using cl100k_base encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(em)\n",
        "# embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__sJx7ZXNfnp",
        "outputId": "b818d186-d8eb-4251-9c0e-52ca61c38c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"Perfectionism is\"\n",
        "result = search.similarity_search(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-fqTV5sIuWS",
        "outputId": "e824843e-2b87-4861-d076-10e32db1af22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.embeddings.openai:Warning: model not found. Using cl100k_base encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnKS46PkIvvR",
        "outputId": "5c2ae0b9-570c-4ded-bebc-4fcd1dda818e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='advance what you want to drop, you remove the sting of shame. Strategic incompetence is admitting that you don’t have time to do everything and something will deliberately go by the wayside during this season of your life. The two options we have now are: \\t1. Attempt more than is humanly possible and fail. \\t2. Choose what to bomb and succeed at a goal that matters. \\t Actions: \\t1. Make a list of three things you could bomb during your goal. \\t2. For time drains you can’t bomb, figure out a way you', metadata={}),\n",
              " Document(page_content='2. Fear: The fear of the future forces you to change the present.  As you choose between fear and a reward, please know that perfectionism will tell you that you don’t need either. Real winners don’t need motivation. They just do their job. They don’t need rewards or punishments, no carrots or sticks. They just put their nose to the grindstone. A reward is cheating. You’re better than that. The hard work is its own reward.  Actions: \\t1. On a scale of 1 to 10, how fun is the goal you might be', metadata={}),\n",
              " Document(page_content='comes along with every endeavour, so you’re hiding from it by doing something that requires no skill. \\tb. Ones that masquerades as productive ones: They make you feel like you’re doing well when in reality you’re not getting anywhere on your most important projects. \\t Here are a few simple ways to identify them: \\t1. If you blink and find yourself working on something besides your real goal, you’ve probably retreated to the first kind of hiding place: the obvious time waster. \\t2. If you ever have', metadata={}),\n",
              " Document(page_content='or its not worth even trying. This coupled with our snowballing goals, we end up not doing anything. We start with I can do something, then start dreaming of bigger things and soon end up feeling inadequate and just give up on the whole affair. We don’t want small growth. We want massive, overnight success. (from chapter 1) Bigger the goal, the bigger the initial rush we get from imagining it. Scientists call this “planning fallacy,” a concept first studied by Daniel Kahneman and Amos Tversky.', metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Your an expert on answering questions from given data. Only use the data provided below to answer the question:\n",
        "DATA:{data}\n",
        "QUESTION:{query}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"data\",\"query\"],\n",
        "    template=template)"
      ],
      "metadata": {
        "id": "LVOoxnhUOwae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.format(data=result,query=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "WvGzpL_PPLCj",
        "outputId": "5e1c7147-3e6f-4548-cc13-95597cc499f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nYour an expert on answering questions from given data. Only use the data provided below to answer the question:\\nDATA:[Document(page_content='advance what you want to drop, you remove the sting of shame. Strategic incompetence is admitting that you don’t have time to do everything and something will deliberately go by the wayside during this season of your life. The two options we have now are: \\\\t1. Attempt more than is humanly possible and fail. \\\\t2. Choose what to bomb and succeed at a goal that matters. \\\\t Actions: \\\\t1. Make a list of three things you could bomb during your goal. \\\\t2. For time drains you can’t bomb, figure out a way you', metadata={}), Document(page_content='2. Fear: The fear of the future forces you to change the present.  As you choose between fear and a reward, please know that perfectionism will tell you that you don’t need either. Real winners don’t need motivation. They just do their job. They don’t need rewards or punishments, no carrots or sticks. They just put their nose to the grindstone. A reward is cheating. You’re better than that. The hard work is its own reward.  Actions: \\\\t1. On a scale of 1 to 10, how fun is the goal you might be', metadata={}), Document(page_content='comes along with every endeavour, so you’re hiding from it by doing something that requires no skill. \\\\tb. Ones that masquerades as productive ones: They make you feel like you’re doing well when in reality you’re not getting anywhere on your most important projects. \\\\t Here are a few simple ways to identify them: \\\\t1. If you blink and find yourself working on something besides your real goal, you’ve probably retreated to the first kind of hiding place: the obvious time waster. \\\\t2. If you ever have', metadata={}), Document(page_content='or its not worth even trying. This coupled with our snowballing goals, we end up not doing anything. We start with I can do something, then start dreaming of bigger things and soon end up feeling inadequate and just give up on the whole affair. We don’t want small growth. We want massive, overnight success. (from chapter 1) Bigger the goal, the bigger the initial rush we get from imagining it. Scientists call this “planning fallacy,” a concept first studied by Daniel Kahneman and Amos Tversky.', metadata={})]\\nQUESTION:Perfectionism is\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pipeline(\n",
        "    prompt.format(data=result,query=query),\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    #offload_folder=\"offload\",\n",
        ")\n",
        "\n",
        "for seq in sequences:\n",
        "    print(f\"Result: {seq['generated_text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP9QE4D9PpS1",
        "outputId": "da6a5229-9b83-42bc-a6c3-8e243d7dc1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Both `max_new_tokens` (=200) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: \n",
            "Your an expert on answering questions from given data. Only use the data provided below to answer the question:\n",
            "DATA:[Document(page_content='advance what you want to drop, you remove the sting of shame. Strategic incompetence is admitting that you don’t have time to do everything and something will deliberately go by the wayside during this season of your life. The two options we have now are: \\t1. Attempt more than is humanly possible and fail. \\t2. Choose what to bomb and succeed at a goal that matters. \\t Actions: \\t1. Make a list of three things you could bomb during your goal. \\t2. For time drains you can’t bomb, figure out a way you', metadata={}), Document(page_content='2. Fear: The fear of the future forces you to change the present.  As you choose between fear and a reward, please know that perfectionism will tell you that you don’t need either. Real winners don’t need motivation. They just do their job. They don’t need rewards or punishments, no carrots or sticks. They just put their nose to the grindstone. A reward is cheating. You’re better than that. The hard work is its own reward.  Actions: \\t1. On a scale of 1 to 10, how fun is the goal you might be', metadata={}), Document(page_content='comes along with every endeavour, so you’re hiding from it by doing something that requires no skill. \\tb. Ones that masquerades as productive ones: They make you feel like you’re doing well when in reality you’re not getting anywhere on your most important projects. \\t Here are a few simple ways to identify them: \\t1. If you blink and find yourself working on something besides your real goal, you’ve probably retreated to the first kind of hiding place: the obvious time waster. \\t2. If you ever have', metadata={}), Document(page_content='or its not worth even trying. This coupled with our snowballing goals, we end up not doing anything. We start with I can do something, then start dreaming of bigger things and soon end up feeling inadequate and just give up on the whole affair. We don’t want small growth. We want massive, overnight success. (from chapter 1) Bigger the goal, the bigger the initial rush we get from imagining it. Scientists call this “planning fallacy,” a concept first studied by Daniel Kahneman and Amos Tversky.', metadata={})]\n",
            "QUESTION:Perfectionism is\n",
            "A. The act of deliberately attempting more than you can humanly do\n",
            "B. The fear of failure\n",
            "C. A strategy for success\n",
            "D. Fear of the future\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NYvC7knP7_F",
        "outputId": "ffa5f020-7402-4ccd-ca49-106c586eb116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"\\nYour an expert on answering questions from given data. Only use the data provided below to answer the question:\\nDATA:[Document(page_content='advance what you want to drop, you remove the sting of shame. Strategic incompetence is admitting that you don’t have time to do everything and something will deliberately go by the wayside during this season of your life. The two options we have now are: \\\\t1. Attempt more than is humanly possible and fail. \\\\t2. Choose what to bomb and succeed at a goal that matters. \\\\t Actions: \\\\t1. Make a list of three things you could bomb during your goal. \\\\t2. For time drains you can’t bomb, figure out a way you', metadata={}), Document(page_content='2. Fear: The fear of the future forces you to change the present.  As you choose between fear and a reward, please know that perfectionism will tell you that you don’t need either. Real winners don’t need motivation. They just do their job. They don’t need rewards or punishments, no carrots or sticks. They just put their nose to the grindstone. A reward is cheating. You’re better than that. The hard work is its own reward.  Actions: \\\\t1. On a scale of 1 to 10, how fun is the goal you might be', metadata={}), Document(page_content='comes along with every endeavour, so you’re hiding from it by doing something that requires no skill. \\\\tb. Ones that masquerades as productive ones: They make you feel like you’re doing well when in reality you’re not getting anywhere on your most important projects. \\\\t Here are a few simple ways to identify them: \\\\t1. If you blink and find yourself working on something besides your real goal, you’ve probably retreated to the first kind of hiding place: the obvious time waster. \\\\t2. If you ever have', metadata={}), Document(page_content='or its not worth even trying. This coupled with our snowballing goals, we end up not doing anything. We start with I can do something, then start dreaming of bigger things and soon end up feeling inadequate and just give up on the whole affair. We don’t want small growth. We want massive, overnight success. (from chapter 1) Bigger the goal, the bigger the initial rush we get from imagining it. Scientists call this “planning fallacy,” a concept first studied by Daniel Kahneman and Amos Tversky.', metadata={})]\\nQUESTION:Perfectionism is\\n1\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "llm = HuggingFacePipeline(pipeline=pipeline,verbose=True,model_id=model)"
      ],
      "metadata": {
        "id": "8eNgHnRvR3IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "# llm(prompt.format(concept=\"DNA\", x=\"5\"))\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "chain.run(data=result,query=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "UBcZ8Ts_SFQ9",
        "outputId": "780427d2-dd4f-46cc-9de0-17b2e54710be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Both `max_new_tokens` (=200) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a) a fear of failure\\nb) a fear of the future\\nc) a fear of not being good enough\\nd) a fear of not being able to do everything\\ne) a fear of not being able to do anything\\nf) a fear of not being able to do everything\\ng) a fear of not being able to do anything\\nh) a fear of not being able to do anything\\ni) a fear of not being able to do anything\\nj) a fear of not being able to do anything\\nk) a fear of not being able to do anything\\nl) a fear of not being able to do anything\\nm) a fear of not being able to do anything\\nn) a fear of not being able to do anything\\no) a fear of not being able to do anything\\np) a fear of not being able to do anything\\nq) a fear of not being able to do anything\\nr) a fear of not being'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v57oGpijV1fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt.format(data=result,query=query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "Vj3RIWkxTlkZ",
        "outputId": "4f3598dc-a364-476a-f203-6b8fd41f52ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Both `max_new_tokens` (=200) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a) a fear of failure\\nb) a fear of the future\\nc) a fear of not being good enough\\nd) a fear of not being able to do everything\\ne) a fear of not being able to do anything\\nf) a fear of not being able to do everything\\ng) a fear of not being able to do anything\\nh) a fear of not being able to do anything\\ni) a fear of not being able to do anything\\nj) a fear of not being able to do anything\\nk) a fear of not being able to do anything\\nl) a fear of not being able to do anything\\nm) a fear of not being able to do anything\\nn) a fear of not being able to do anything\\no) a fear of not being able to do anything\\np) a fear of not being able to do anything\\nq) a fear of not being able to do anything\\nr) a fear of not being'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Summarize the following:\n",
        "advance what you want to drop, you remove the sting of shame. Strategic incompetence is admitting that you don’t have time to do everything and something will deliberately go by the wayside during this season of your life. The two options we have now are: \\\\t1. Attempt more than is humanly possible and fail. \\\\t2. Choose what to bomb and succeed at a goal that matters. \\\\t Actions: \\\\t1. Make a list of three things you could bomb during your goal. \\\\t2. For time drains you can’t bomb, figure out a way you\\n\\n\n",
        "2. Fear: The fear of the future forces you to change the present.  As you choose between fear and a reward, please know that perfectionism will tell you that you don’t need either. Real winners don’t need motivation. They just do their job. They don’t need rewards or punishments, no carrots or sticks. They just put their nose to the grindstone. A reward is cheating. You’re better than that. The hard work is its own reward.  Actions: \\\\t1. On a scale of 1 to 10, how fun is the goal you might be\n",
        "comes along with every endeavour, so you’re hiding from it by doing something that requires no skill. \\\\tb. Ones that masquerades as productive ones: They make you feel like you’re doing well when in reality you’re not getting anywhere on your most important projects. \\\\t Here are a few simple ways to identify them: \\\\t1. If you blink and find yourself working on something besides your real goal, you’ve probably retreated to the first kind of hiding place: the obvious time waster. \\\\t2. If you ever have\\n\\n\n",
        "or its not worth even trying. This coupled with our snowballing goals, we end up not doing anything. We start with I can do something, then start dreaming of bigger things and soon end up feeling inadequate and just give up on the whole affair. We don’t want small growth. We want massive, overnight success. (from chapter 1) Bigger the goal, the bigger the initial rush we get from imagining it. Scientists call this “planning fallacy,” a concept first studied by Daniel Kahneman and Amos Tversky.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "c5ZdaiwRV2rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pipeline(\n",
        "    prompt,\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    #offload_folder=\"offload\",\n",
        ")\n",
        "\n",
        "for seq in sequences:\n",
        "    print(f\"Result: {seq['generated_text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9FWDY1mWhME",
        "outputId": "22fa5a79-0d23-4103-dfd3-97a176f1b938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 509, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: \n",
            "Summarize the following:\n",
            "advance what you want to drop, you remove the sting of shame. Strategic incompetence is admitting that you don’t have time to do everything and something will deliberately go by the wayside during this season of your life. The two options we have now are: \\t1. Attempt more than is humanly possible and fail. \\t2. Choose what to bomb and succeed at a goal that matters. \\t Actions: \\t1. Make a list of three things you could bomb during your goal. \\t2. For time drains you can’t bomb, figure out a way you\n",
            "\n",
            "\n",
            "2. Fear: The fear of the future forces you to change the present.  As you choose between fear and a reward, please know that perfectionism will tell you that you don’t need either. Real winners don’t need motivation. They just do their job. They don’t need rewards or punishments, no carrots or sticks. They just put their nose to the grindstone. A reward is cheating. You’re better than that. The hard work is its own reward.  Actions: \\t1. On a scale of 1 to 10, how fun is the goal you might be', metadata={}), Document(page_content='comes along with every endeavour, so you’re hiding from it by doing something that requires no skill. \\tb. Ones that masquerades as productive ones: They make you feel like you’re doing well when in reality you’re not getting anywhere on your most important projects. \\t Here are a few simple ways to identify them: \\t1. If you blink and find yourself working on something besides your real goal, you’ve probably retreated to the first kind of hiding place: the obvious time waster. \\t2. If you ever have\n",
            "\n",
            "\n",
            "or its not worth even trying. This coupled with our snowballing goals, we end up not doing anything. We start with I can do something, then start dreaming of bigger things and soon end up feeling inadequate and just give up on the whole affair. We don’t want small growth. We want massive, overnight success. (from chapter 1) Bigger the goal, the bigger the initial rush we get from imagining it. Scientists call this “planning fallacy,” a concept first studied by Daniel Kahneman and Amos Tversky.\n",
            "We\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBBura-ZW1Ws",
        "outputId": "d947ba3d-d4ef-4ccd-8908-51e2023e1e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"\\nSummarize the following:\\nadvance what you want to drop, you remove the sting of shame. Strategic incompetence is admitting that you don’t have time to do everything and something will deliberately go by the wayside during this season of your life. The two options we have now are: \\\\t1. Attempt more than is humanly possible and fail. \\\\t2. Choose what to bomb and succeed at a goal that matters. \\\\t Actions: \\\\t1. Make a list of three things you could bomb during your goal. \\\\t2. For time drains you can’t bomb, figure out a way you\\n\\n\\n2. Fear: The fear of the future forces you to change the present.  As you choose between fear and a reward, please know that perfectionism will tell you that you don’t need either. Real winners don’t need motivation. They just do their job. They don’t need rewards or punishments, no carrots or sticks. They just put their nose to the grindstone. A reward is cheating. You’re better than that. The hard work is its own reward.  Actions: \\\\t1. On a scale of 1 to 10, how fun is the goal you might be', metadata={}), Document(page_content='comes along with every endeavour, so you’re hiding from it by doing something that requires no skill. \\\\tb. Ones that masquerades as productive ones: They make you feel like you’re doing well when in reality you’re not getting anywhere on your most important projects. \\\\t Here are a few simple ways to identify them: \\\\t1. If you blink and find yourself working on something besides your real goal, you’ve probably retreated to the first kind of hiding place: the obvious time waster. \\\\t2. If you ever have\\n\\n\\nor its not worth even trying. This coupled with our snowballing goals, we end up not doing anything. We start with I can do something, then start dreaming of bigger things and soon end up feeling inadequate and just give up on the whole affair. We don’t want small growth. We want massive, overnight success. (from chapter 1) Bigger the goal, the bigger the initial rush we get from imagining it. Scientists call this “planning fallacy,” a concept first studied by Daniel Kahneman and Amos Tversky.\\nWe\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "glgcx9ixvcGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IexuuJGzvchh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKoQIUMxvcoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import retriever\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=search.as_retriever())"
      ],
      "metadata": {
        "id": "DNaaf79Lvdhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"What is Perfection?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "hdqj-uG5vcuq",
        "outputId": "596a4ab8-47d2-4b3d-e220-ec198967a52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.embeddings.openai:Warning: model not found. Using cl100k_base encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Both `max_new_tokens` (=200) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Perfection is the process of making something as good as it can be. It is the process of refining and improving something until it is as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can be. It is the process of making something as good as it can'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}